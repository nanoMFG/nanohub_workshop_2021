{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning for SEM Image Segmentation in Materials Science\n",
    "\n",
    "## *Training a U-Net model to segment microscopy images*\n",
    "\n",
    "In this tutorial will learn how to train a U-Net model to segment a scanning electron microscopy image of graphene on a substrate.\n",
    "\n",
    "**Outline:**\n",
    "1. Define the parameters\n",
    "2. Define the U-Net Architecture\n",
    "3. Pre-process the image and start training\n",
    "4. Test the model\n",
    "\n",
    "**Get started:** Click \"Shift-Enter\" to run the code in each cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <ins>Let's begin</ins>\n",
    "\n",
    "We will first import the relevant Python libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "import tensorflow as tf\n",
    "from keras.optimizers import *\n",
    "import keras.backend as K\n",
    "from keras.utils import plot_model\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <ins>Define Paramters</ins>\n",
    "\n",
    "Define the number of epochs and the initial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nepochs=5 # define the number of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_mask_paths = [(\"../data/masks/image_%d.tif\"%i,\"../data/masks/image_%d_mask.png\"%i) for i in range(1,19)] # store the image file paths for the training data\n",
    "\n",
    "# divide the data into training and test data\n",
    "test_paths = image_mask_paths[:int(2)]\n",
    "train_paths = image_mask_paths[int(2):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <ins>Define the U-Net Architecture</ins>\n",
    "\n",
    "We will be using a smaller version of the same architecture in the interest of time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FULL U-NET ARCHITECTURE: ###\n",
    "#\n",
    "# input_size = (256,256,1)\n",
    "# \n",
    "# inputs = Input(input_size)\n",
    "# conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "# conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "# pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "# \n",
    "# conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "# conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "# pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "#     \n",
    "# conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "# conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "# pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "#   \n",
    "# conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "# conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "# drop4 = Dropout(0.5)(conv4)\n",
    "# pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "# \n",
    "# conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
    "# conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "# drop5 = Dropout(0.5)(conv5)\n",
    "# \n",
    "# up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
    "# merge6 = concatenate([drop4,up6], axis = 3)\n",
    "# conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "# conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "# \n",
    "# up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
    "# merge7 = concatenate([conv3,up7], axis = 3)\n",
    "# conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "# conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "# \n",
    "# up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
    "# merge8 = concatenate([conv2,up8], axis = 3)\n",
    "# conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "# conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "# \n",
    "# up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
    "# merge9 = concatenate([conv1,up9], axis = 3)\n",
    "# conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
    "# conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "# conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "# conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n",
    "# \n",
    "# model = Model(input = inputs, output = conv10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# U-Net Architecture. Note that the output of each layer is the input of the next layer. \n",
    "\n",
    "input_size = (256,256,1) # define size of input image \n",
    "\n",
    "inputs = Input(input_size) # define input layer\n",
    "conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs) # define first convolutional layer\n",
    "conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1) # define second convolutional layer\n",
    "pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)# perform max pooling\n",
    "\n",
    "# repeat the above steps\n",
    "conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    \n",
    "conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "# perform up-conversion\n",
    "up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv3))\n",
    "merge8 = concatenate([conv2,up8], axis = 3) # Perform the \"copy and crop\" step\n",
    "conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "\n",
    "up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
    "merge9 = concatenate([conv1,up9], axis = 3)\n",
    "conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
    "conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9) # perform a final convolution to receive the output as an image\n",
    "\n",
    "model = Model(input = inputs, output = conv10) # define the model itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define other model parameters and compile the model\n",
    "optimizer = RMSprop \n",
    "model.compile(optimizer = optimizer(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <ins>Pre-process image and start training</ins>\n",
    "\n",
    "Convert the image to the input size and shape. Train the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(nepochs):\n",
    "    shuffle(train_paths) # shuffle the trainig paths to prevent over-fitting\n",
    "    out_imgs = np.zeros((16,)+(256,256)+(1,)) # define the input images for the model\n",
    "    out_masks = np.zeros((16,)+(256,256)+(1,)) # define the input masks for the model\n",
    "    for i, img_mask_path in enumerate(train_paths):\n",
    "        img, mask = read_data(img_mask_path) # import images, save as array, crop and resize the image to (256,256,1)\n",
    "        out_imgs[i,...] = img # create single array of images\n",
    "        out_masks[i,...] = mask # create single array of masks\n",
    "        \n",
    "    loss = model.train_on_batch(out_imgs,out_masks) # train the model\n",
    "    metric_names = model.metrics_names # store the metric names\n",
    "    \n",
    "    print(\"epoch: \", epoch, \"; training loss: \", loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <ins>Test the model</ins>\n",
    "\n",
    "Tets the trained model on the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = []\n",
    "\n",
    "# pre-process the testing data\n",
    "out_imgs = np.zeros((16,)+(256,256)+(1,))\n",
    "out_masks = np.zeros((16,)+(256,256)+(1,))\n",
    "for i, img_mask_path in enumerate(test_paths):\n",
    "    img, mask = read_data(img_mask_path)\n",
    "    out_imgs[i,...] = img\n",
    "    out_masks[i,...] = mask\n",
    "\n",
    "# makes a prediction for our test images using the trained model\n",
    "prediction = model.predict_on_batch(out_imgs)\n",
    "\n",
    "# output the loss for the testing data\n",
    "test_loss.append(model.test_on_batch(out_imgs,out_masks))\n",
    "test_loss = np.mean(np.array(test_loss),axis=0)\n",
    "\n",
    "print(\"testing loss: \", test_loss[1])\n",
    "\n",
    "#save the model to a file\n",
    "save_model_unet(model,epoch,test_loss[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
